# BIG DATA #

## INTRODUCTION ##
Big data is a collection of data which is huge in volume , grows exponentially with time.
It is a combination of structure, semi-structured or unstructured data.
Due to the huge volume and complexity, traditional databases fails to store or process it.

####  CHARATERISTICS OF BIG  DATA ####

Characteristics which need to be considered while dealing with Big data solution.
 - Volume – deals with amount of data
 - Value – quality of data (reliable and valuable data that we store, process, analyse)
 - Velocity – speed of generation of data.(i.e) speed in transaction and speed in processing
 - Variety – different formats of data (structured / semi-structured/unstructured) from various sources 

#### HDFS ####
Hadoop distributed file system HDFS.
Hadoop consists of HDFS and Map Reduce.
Hadoop framework consists of HDFS, MR, Hive.

#### METADATA ####
Metadata is data about data. It provides additional information about a specific set of data.

#### HADOOP ####
Hadoop is a distributed framework that makes it easier to process large data sets that reside in cluster of computers.
Hadoop provides a method to access the data that is distributed among multiple cluster, process the data and manage the resources.
Hadoop follows master slave architecture.
The modules in the hadoop are
  - HDFS Hadoop Distributed File System 
  - Yarn
  - Map Reduce
  
#### HDFS ####
Similar to data residing in a local file system of a computer, in hadoop data resides in a distributed file system called Hadoop Distributed File System.
This takes care of the storage part of hadoop applications.

